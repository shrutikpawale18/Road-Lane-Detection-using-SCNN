{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1ZFqycQYVAmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e043bc-d495-4c4b-9d95-08d2a8f39aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "QlrSc0p0j7MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2794FbI4sWf3",
        "outputId": "6da2c702-570d-4079-c0c2-fdb5c6d7c971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torchfile\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5693 sha256=1a69bbc36a4191696c463e8201c362466c392790be9f8ddba7f70b35871f93d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/e9/87/1c51daf8e468d5c14931f8ac3344880f903ba96b063675cac2\n",
            "Successfully built torchfile\n",
            "Installing collected packages: torchfile\n",
            "Successfully installed torchfile-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset_Path = dict(\n",
        "    CULane = \"/content/drive/MyDrive/CULane_path\",\n",
        ")"
      ],
      "metadata": {
        "id": "xInoc6wnRTCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CULane(Dataset):\n",
        "    def __init__(self, path, image_set, transforms=None):\n",
        "        super(CULane, self).__init__()\n",
        "        assert image_set in ('train', 'val', 'test'), \"image_set is not valid!\"\n",
        "        self.data_dir_path = path\n",
        "        self.image_set = image_set\n",
        "        self.transforms = transforms\n",
        "\n",
        "        if image_set != 'test':\n",
        "            self.createIndex()\n",
        "        else:\n",
        "            self.createIndex_test()\n",
        "\n",
        "\n",
        "    def createIndex(self):\n",
        "        listfile = os.path.join(self.data_dir_path, \"list\", \"{}_gt.txt\".format(self.image_set))\n",
        "\n",
        "        self.img_list = []\n",
        "        self.segLabel_list = []\n",
        "        self.exist_list = []\n",
        "        with open(listfile) as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                l = line.split(\" \")\n",
        "                if '/driver_23_30frame' in l[0] or '/driver_182_30frame' in l[0]:\n",
        "                    continue\n",
        "                else:\n",
        "                    self.img_list.append(os.path.join(self.data_dir_path, l[0][1:]))   # l[0][1:]  get rid of the first '/' so as for os.path.join\n",
        "                    self.segLabel_list.append(os.path.join(self.data_dir_path, l[1][1:]))\n",
        "                    self.exist_list.append([int(x) for x in l[2:]])\n",
        "\n",
        "    def createIndex_test(self):\n",
        "        listfile = os.path.join(self.data_dir_path, \"list\", \"{}.txt\".format(self.image_set))\n",
        "\n",
        "        self.img_list = []\n",
        "        with open(listfile) as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if '/driver_193_90frame' in line or '/driver_100_30frame' in line:\n",
        "                    continue\n",
        "                else:\n",
        "                    self.img_list.append(os.path.join(self.data_dir_path, line[1:]))  # l[0][1:]  get rid of the first '/' so as for os.path.join\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.img_list[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.image_set != 'test':\n",
        "            segLabel = cv2.imread(self.segLabel_list[idx])[:, :, 0]\n",
        "            exist = np.array(self.exist_list[idx])\n",
        "        else:\n",
        "            segLabel = None\n",
        "            exist = None\n",
        "\n",
        "        sample = {'img': img,\n",
        "                  'segLabel': segLabel,\n",
        "                  'exist': exist,\n",
        "                  'img_name': self.img_list[idx]}\n",
        "        if self.transforms is not None:\n",
        "            sample = self.transforms(sample)\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    @staticmethod\n",
        "    def collate(batch):\n",
        "        if isinstance(batch[0]['img'], torch.Tensor):\n",
        "            img = torch.stack([b['img'] for b in batch])\n",
        "        else:\n",
        "            img = [b['img'] for b in batch]\n",
        "\n",
        "        if batch[0]['segLabel'] is None:\n",
        "            segLabel = None\n",
        "            exist = None\n",
        "        elif isinstance(batch[0]['segLabel'], torch.Tensor):\n",
        "            segLabel = torch.stack([b['segLabel'] for b in batch])\n",
        "            exist = torch.stack([b['exist'] for b in batch])\n",
        "        else:\n",
        "            segLabel = [b['segLabel'] for b in batch]\n",
        "            exist = [b['exist'] for b in batch]\n",
        "        samples = {'img': img,\n",
        "                  'segLabel': segLabel,\n",
        "                  'exist': exist,\n",
        "                  'img_name': [x['img_name'] for x in batch]}\n",
        "\n",
        "        return samples\n"
      ],
      "metadata": {
        "id": "7ifMIPAizc_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getLane_CULane(prob_map, y_px_gap, pts, thresh, resize_shape=None):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    ----------\n",
        "    prob_map: prob map for single lane, np array size (h, w)\n",
        "    resize_shape:  reshape size target, (H, W)\n",
        "    Return:\n",
        "    ----------\n",
        "    coords: x coords bottom up every y_px_gap px, 0 for non-exist, in resized shape\n",
        "    \"\"\"\n",
        "    if resize_shape is None:\n",
        "        resize_shape = prob_map.shape\n",
        "    h, w = prob_map.shape\n",
        "    H, W = resize_shape\n",
        "\n",
        "    coords = np.zeros(pts)\n",
        "    for i in range(pts):\n",
        "        y = int(h - i * y_px_gap / H * h - 1)\n",
        "        if y < 0:\n",
        "            break\n",
        "        line = prob_map[y, :]\n",
        "        id = np.argmax(line)\n",
        "        if line[id] > thresh:\n",
        "            coords[i] = int(id / w * W)\n",
        "    if (coords > 0).sum() < 2:\n",
        "        coords = np.zeros(pts)\n",
        "    return coords\n",
        "\n",
        "\n",
        "def prob2lines_CULane(seg_pred, exist, resize_shape=None, smooth=True, y_px_gap=20, pts=None, thresh=0.3):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    ----------\n",
        "    seg_pred: np.array size (5, h, w)\n",
        "    resize_shape:  reshape size target, (H, W)\n",
        "    exist:   list of existence, e.g. [0, 1, 1, 0]\n",
        "    smooth:  whether to smooth the probability or not\n",
        "    y_px_gap: y pixel gap for sampling\n",
        "    pts:     how many points for one lane\n",
        "    thresh:  probability threshold\n",
        "    Return:\n",
        "    ----------\n",
        "    coordinates: [x, y] list of lanes, e.g.: [ [[9, 569], [50, 549]] ,[[630, 569], [647, 549]] ]\n",
        "    \"\"\"\n",
        "    if resize_shape is None:\n",
        "        resize_shape = seg_pred.shape[1:]  # seg_pred (5, h, w)\n",
        "    _, h, w = seg_pred.shape\n",
        "    H, W = resize_shape\n",
        "    coordinates = []\n",
        "\n",
        "    if pts is None:\n",
        "        pts = round(H / 2 / y_px_gap)\n",
        "\n",
        "    seg_pred = np.ascontiguousarray(np.transpose(seg_pred, (1, 2, 0)))\n",
        "    for i in range(4):\n",
        "        prob_map = seg_pred[..., i + 1]\n",
        "        if smooth:\n",
        "            prob_map = cv2.blur(prob_map, (9, 9), borderType=cv2.BORDER_REPLICATE)\n",
        "        if exist[i] > 0:\n",
        "            coords = getLane_CULane(prob_map, y_px_gap, pts, thresh, resize_shape)\n",
        "            if (coords>0).sum() < 2:\n",
        "                continue\n",
        "            coordinates.append([[coords[j], H - 1 - j * y_px_gap] for j in range(pts) if coords[j] > 0])\n",
        "\n",
        "    return coordinates\n"
      ],
      "metadata": {
        "id": "Ln4wVAK61gUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms import Normalize as Normalize_th\n",
        "\n",
        "\n",
        "class CustomTransform:\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__class__.__name__\n",
        "\n",
        "    def __eq__(self, name):\n",
        "        return str(self) == name\n",
        "\n",
        "    def __iter__(self):\n",
        "        def iter_fn():\n",
        "            for t in [self]:\n",
        "                yield t\n",
        "        return iter_fn()\n",
        "\n",
        "    def __contains__(self, name):\n",
        "        for t in self.__iter__():\n",
        "            if isinstance(t, Compose):\n",
        "                if name in t:\n",
        "                    return True\n",
        "            elif name == t:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "\n",
        "class Compose(CustomTransform):\n",
        "    \"\"\"\n",
        "    All transform in Compose should be able to accept two non None variable, img and boxes\n",
        "    \"\"\"\n",
        "    def __init__(self, *transforms):\n",
        "        self.transforms = [*transforms]\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        for t in self.transforms:\n",
        "            sample = t(sample)\n",
        "        return sample\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.transforms)\n",
        "\n",
        "    def modules(self):\n",
        "        yield self\n",
        "        for t in self.transforms:\n",
        "            if isinstance(t, Compose):\n",
        "                for _t in t.modules():\n",
        "                    yield _t\n",
        "            else:\n",
        "                yield t\n",
        "\n",
        "\n",
        "class Resize(CustomTransform):\n",
        "    def __init__(self, size):\n",
        "        if isinstance(size, int):\n",
        "            size = (size, size)\n",
        "        self.size = size  #(W, H)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        img = sample.get('img')\n",
        "        segLabel = sample.get('segLabel', None)\n",
        "\n",
        "        img = cv2.resize(img, self.size, interpolation=cv2.INTER_CUBIC)\n",
        "        if segLabel is not None:\n",
        "            segLabel = cv2.resize(segLabel, self.size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        _sample = sample.copy()\n",
        "        _sample['img'] = img\n",
        "        _sample['segLabel'] = segLabel\n",
        "        return _sample\n",
        "\n",
        "    def reset_size(self, size):\n",
        "        if isinstance(size, int):\n",
        "            size = (size, size)\n",
        "        self.size = size\n",
        "\n",
        "\n",
        "class RandomResize(Resize):\n",
        "    \"\"\"\n",
        "    Resize to (w, h), where w randomly samples from (minW, maxW) and h randomly samples from (minH, maxH)\n",
        "    \"\"\"\n",
        "    def __init__(self, minW, maxW, minH=None, maxH=None, batch=False):\n",
        "        if minH is None or maxH is None:\n",
        "            minH, maxH = minW, maxW\n",
        "        super(RandomResize, self).__init__((minW, minH))\n",
        "        self.minW = minW\n",
        "        self.maxW = maxW\n",
        "        self.minH = minH\n",
        "        self.maxH = maxH\n",
        "        self.batch = batch\n",
        "\n",
        "    def random_set_size(self):\n",
        "        w = np.random.randint(self.minW, self.maxW+1)\n",
        "        h = np.random.randint(self.minH, self.maxH+1)\n",
        "        self.reset_size((w, h))\n",
        "\n",
        "\n",
        "class Rotation(CustomTransform):\n",
        "    def __init__(self, theta):\n",
        "        self.theta = theta\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        img = sample.get('img')\n",
        "        segLabel = sample.get('segLabel', None)\n",
        "\n",
        "        u = np.random.uniform()\n",
        "        degree = (u-0.5) * self.theta\n",
        "        R = cv2.getRotationMatrix2D((img.shape[1]//2, img.shape[0]//2), degree, 1)\n",
        "        img = cv2.warpAffine(img, R, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
        "        if segLabel is not None:\n",
        "            segLabel = cv2.warpAffine(segLabel, R, (segLabel.shape[1], segLabel.shape[0]), flags=cv2.INTER_NEAREST)\n",
        "\n",
        "        _sample = sample.copy()\n",
        "        _sample['img'] = img\n",
        "        _sample['segLabel'] = segLabel\n",
        "        return _sample\n",
        "\n",
        "    def reset_theta(self, theta):\n",
        "        self.theta = theta\n",
        "\n",
        "\n",
        "class Normalize(CustomTransform):\n",
        "    def __init__(self, mean, std):\n",
        "        self.transform = Normalize_th(mean, std)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        img = sample.get('img')\n",
        "\n",
        "        img = self.transform(img)\n",
        "\n",
        "        _sample = sample.copy()\n",
        "        _sample['img'] = img\n",
        "        return _sample\n",
        "\n",
        "\n",
        "class ToTensor(CustomTransform):\n",
        "    def __init__(self, dtype=torch.float):\n",
        "        self.dtype=dtype\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        img = sample.get('img')\n",
        "        segLabel = sample.get('segLabel', None)\n",
        "        exist = sample.get('exist', None)\n",
        "\n",
        "        img = img.transpose(2, 0, 1)\n",
        "        img = torch.from_numpy(img).type(self.dtype) / 255.\n",
        "        if segLabel is not None:\n",
        "            segLabel = torch.from_numpy(segLabel).type(torch.long)\n",
        "        if exist is not None:\n",
        "            exist = torch.from_numpy(exist).type(torch.float32)  # BCEloss requires float tensor\n",
        "\n",
        "        _sample = sample.copy()\n",
        "        _sample['img'] = img\n",
        "        _sample['segLabel'] = segLabel\n",
        "        _sample['exist'] = exist\n",
        "        return _sample\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AcZ7pweO2FnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "class RandomFlip(CustomTransform):\n",
        "    def __init__(self, prob_x=0, prob_y=0):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        ----------\n",
        "        prob_x: range [0, 1], probability to use horizontal flip, setting to 0 means disabling flip\n",
        "        prob_y: range [0, 1], probability to use vertical flip\n",
        "        \"\"\"\n",
        "        self.prob_x = prob_x\n",
        "        self.prob_y = prob_y\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        img = sample.get('img').copy()\n",
        "        segLabel = sample.get('segLabel', None)\n",
        "        if segLabel is not None:\n",
        "            segLabel = segLabel.copy()\n",
        "\n",
        "        flip_x = np.random.choice([False, True], p=(1 - self.prob_x, self.prob_x))\n",
        "        flip_y = np.random.choice([False, True], p=(1 - self.prob_y, self.prob_y))\n",
        "        if flip_x:\n",
        "            img = np.ascontiguousarray(np.flip(img, axis=1))\n",
        "            if segLabel is not None:\n",
        "                segLabel = np.ascontiguousarray(np.flip(segLabel, axis=1))\n",
        "\n",
        "        if flip_y:\n",
        "            img = np.ascontiguousarray(np.flip(img, axis=0))\n",
        "            if segLabel is not None:\n",
        "                segLabel = np.ascontiguousarray(np.flip(segLabel, axis=0))\n",
        "\n",
        "        _sample = sample.copy()\n",
        "        _sample['img'] = img\n",
        "        _sample['segLabel'] = segLabel\n",
        "        return _sample\n",
        "\n",
        "\n",
        "class Darkness(CustomTransform):\n",
        "    def __init__(self, coeff):\n",
        "        assert coeff >= 1., \"Darkness coefficient must be greater than 1\"\n",
        "        self.coeff = coeff\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        img = sample.get('img')\n",
        "        coeff = np.random.uniform(1., self.coeff)\n",
        "        img = (img.astype('float32') / coeff).astype('uint8')\n",
        "\n",
        "        _sample = sample.copy()\n",
        "        _sample['img'] = img\n",
        "        return _sample\n"
      ],
      "metadata": {
        "id": "P2u4L1Vd2MEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "\n",
        "class PolyLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, pow, max_iter, min_lrs=1e-20, last_epoch=-1, warmup=0):\n",
        "        \"\"\"\n",
        "        :param warmup: how many steps for linearly warmup lr\n",
        "        \"\"\"\n",
        "        self.pow = pow\n",
        "        self.max_iter = max_iter\n",
        "        if not isinstance(min_lrs, list) and not isinstance(min_lrs, tuple):\n",
        "            self.min_lrs = [min_lrs] * len(optimizer.param_groups)\n",
        "\n",
        "        assert isinstance(warmup, int), \"The type of warmup is incorrect, got {}\".format(type(warmup))\n",
        "        self.warmup = max(warmup, 0)\n",
        "\n",
        "        super(PolyLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self.last_epoch < self.warmup:\n",
        "            return [base_lr / self.warmup * (self.last_epoch+1) for base_lr in self.base_lrs]\n",
        "\n",
        "        if self.last_epoch < self.max_iter:\n",
        "            coeff = (1 - (self.last_epoch-self.warmup) / (self.max_iter-self.warmup)) ** self.pow\n",
        "        else:\n",
        "            coeff = 0\n",
        "        return [(base_lr - min_lr) * coeff + min_lr\n",
        "                for base_lr, min_lr in zip(self.base_lrs, self.min_lrs)]\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Code copied from pytorch-tutorial https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/04-utils/tensorboard/logger.py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import scipy.misc\n",
        "try:\n",
        "    from StringIO import StringIO  # Python 2.7\n",
        "except ImportError:\n",
        "    from io import BytesIO         # Python 3.x\n",
        "\n",
        "\n",
        "class TensorBoard(object):\n",
        "\n",
        "    def __init__(self, log_dir):\n",
        "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
        "        self.writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "    def scalar_summary(self, tag, value, step):\n",
        "        \"\"\"Log a scalar variable.\"\"\"\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "\n",
        "    def image_summary(self, tag, images, step):\n",
        "        \"\"\"Log a list of images.\"\"\"\n",
        "\n",
        "        img_summaries = []\n",
        "        for i, img in enumerate(images):\n",
        "            # Write the image to a string\n",
        "            try:\n",
        "                s = StringIO()\n",
        "            except:\n",
        "                s = BytesIO()\n",
        "            # scipy.misc.toimage(img).save(s, format=\"png\")\n",
        "            Image.fromarray(img).save(s, format='png')\n",
        "\n",
        "\n",
        "            # Create an Image object\n",
        "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
        "                                       height=img.shape[0],\n",
        "                                       width=img.shape[1])\n",
        "            # Create a Summary value\n",
        "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=img_summaries)\n",
        "        self.writer.add_summary(summary, step)\n",
        "\n",
        "    def histo_summary(self, tag, values, step, bins=1000):\n",
        "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
        "\n",
        "        # Create a histogram using numpy\n",
        "        counts, bin_edges = np.histogram(values, bins=bins)\n",
        "\n",
        "        # Fill the fields of the histogram proto\n",
        "        hist = tf.HistogramProto()\n",
        "        hist.min = float(np.min(values))\n",
        "        hist.max = float(np.max(values))\n",
        "        hist.num = int(np.prod(values.shape))\n",
        "        hist.sum = float(np.sum(values))\n",
        "        hist.sum_squares = float(np.sum(values**2))\n",
        "\n",
        "        # Drop the start of the first bin\n",
        "        bin_edges = bin_edges[1:]\n",
        "\n",
        "        # Add bin edges and counts\n",
        "        for edge in bin_edges:\n",
        "            hist.bucket_limit.append(edge)\n",
        "        for c in counts:\n",
        "            hist.bucket.append(c)\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "        self.writer.flush()\n"
      ],
      "metadata": {
        "id": "GEup3HuO3q__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class SCNN(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size,\n",
        "            ms_ks=9,\n",
        "            pretrained=True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Argument\n",
        "            ms_ks: kernel size in message passing conv\n",
        "        \"\"\"\n",
        "        super(SCNN, self).__init__()\n",
        "        self.pretrained = pretrained\n",
        "        self.net_init(input_size, ms_ks)\n",
        "        if not pretrained:\n",
        "            self.weight_init()\n",
        "\n",
        "        self.scale_background = 0.4\n",
        "        self.scale_seg = 1.0\n",
        "        self.scale_exist = 0.1\n",
        "\n",
        "        self.ce_loss = nn.CrossEntropyLoss(weight=torch.tensor([self.scale_background, 1, 1, 1, 1]))\n",
        "        self.bce_loss = nn.BCELoss()\n",
        "\n",
        "    def forward(self, img, seg_gt=None, exist_gt=None):\n",
        "        x = self.backbone(img)\n",
        "        x = self.layer1(x)\n",
        "        x = self.message_passing_forward(x)\n",
        "        x = self.layer2(x)\n",
        "\n",
        "        seg_pred = F.interpolate(x, scale_factor=8, mode='bilinear', align_corners=True)\n",
        "        x = self.layer3(x)\n",
        "        x = x.view(-1, self.fc_input_feature)\n",
        "        exist_pred = self.fc(x)\n",
        "\n",
        "        if seg_gt is not None and exist_gt is not None:\n",
        "            loss_seg = self.ce_loss(seg_pred, seg_gt)\n",
        "            loss_exist = self.bce_loss(exist_pred, exist_gt)\n",
        "            loss = loss_seg * self.scale_seg + loss_exist * self.scale_exist\n",
        "        else:\n",
        "            loss_seg = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
        "            loss_exist = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
        "            loss = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
        "\n",
        "        return seg_pred, exist_pred, loss_seg, loss_exist, loss\n",
        "\n",
        "    def message_passing_forward(self, x):\n",
        "        Vertical = [True, True, False, False]\n",
        "        Reverse = [False, True, False, True]\n",
        "        for ms_conv, v, r in zip(self.message_passing, Vertical, Reverse):\n",
        "            x = self.message_passing_once(x, ms_conv, v, r)\n",
        "        return x\n",
        "\n",
        "    def message_passing_once(self, x, conv, vertical=True, reverse=False):\n",
        "        \"\"\"\n",
        "        Argument:\n",
        "        ----------\n",
        "        x: input tensor\n",
        "        vertical: vertical message passing or horizontal\n",
        "        reverse: False for up-down or left-right, True for down-up or right-left\n",
        "        \"\"\"\n",
        "        nB, C, H, W = x.shape\n",
        "        if vertical:\n",
        "            slices = [x[:, :, i:(i + 1), :] for i in range(H)]\n",
        "            dim = 2\n",
        "        else:\n",
        "            slices = [x[:, :, :, i:(i + 1)] for i in range(W)]\n",
        "            dim = 3\n",
        "        if reverse:\n",
        "            slices = slices[::-1]\n",
        "\n",
        "        out = [slices[0]]\n",
        "        for i in range(1, len(slices)):\n",
        "            out.append(slices[i] + F.relu(conv(out[i - 1])))\n",
        "        if reverse:\n",
        "            out = out[::-1]\n",
        "        return torch.cat(out, dim=dim)\n",
        "\n",
        "    def net_init(self, input_size, ms_ks):\n",
        "        input_w, input_h = input_size\n",
        "        self.fc_input_feature = 5 * int(input_w/16) * int(input_h/16)\n",
        "        self.backbone = models.vgg16_bn(pretrained=self.pretrained).features\n",
        "\n",
        "        # ----------------- process backbone -----------------\n",
        "        for i in [34, 37, 40]:\n",
        "            conv = self.backbone._modules[str(i)]\n",
        "            dilated_conv = nn.Conv2d(\n",
        "                conv.in_channels, conv.out_channels, conv.kernel_size, stride=conv.stride,\n",
        "                padding=tuple(p * 2 for p in conv.padding), dilation=2, bias=(conv.bias is not None)\n",
        "            )\n",
        "            dilated_conv.load_state_dict(conv.state_dict())\n",
        "            self.backbone._modules[str(i)] = dilated_conv\n",
        "        self.backbone._modules.pop('33')\n",
        "        self.backbone._modules.pop('43')\n",
        "\n",
        "        # ----------------- SCNN part -----------------\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, 3, padding=4, dilation=4, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(1024, 128, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()  # (nB, 128, 36, 100)\n",
        "        )\n",
        "\n",
        "        # ----------------- add message passing -----------------\n",
        "        self.message_passing = nn.ModuleList()\n",
        "        self.message_passing.add_module('up_down', nn.Conv2d(128, 128, (1, ms_ks), padding=(0, ms_ks // 2), bias=False))\n",
        "        self.message_passing.add_module('down_up', nn.Conv2d(128, 128, (1, ms_ks), padding=(0, ms_ks // 2), bias=False))\n",
        "        self.message_passing.add_module('left_right',\n",
        "                                        nn.Conv2d(128, 128, (ms_ks, 1), padding=(ms_ks // 2, 0), bias=False))\n",
        "        self.message_passing.add_module('right_left',\n",
        "                                        nn.Conv2d(128, 128, (ms_ks, 1), padding=(ms_ks // 2, 0), bias=False))\n",
        "        # (nB, 128, 36, 100)\n",
        "\n",
        "        # ----------------- SCNN part -----------------\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.Conv2d(128, 5, 1)  # get (nB, 5, 36, 100)\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Softmax(dim=1),  # (nB, 5, 36, 100)\n",
        "            nn.AvgPool2d(2, 2),  # (nB, 5, 18, 50)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.fc_input_feature, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 4),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def weight_init(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.reset_parameters()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data[:] = 1.\n",
        "                m.bias.data.zero_()\n"
      ],
      "metadata": {
        "id": "5xIIbR9j4WXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys"
      ],
      "metadata": {
        "id": "KnfeA0F8P3Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import collections\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchfile\n",
        "\n",
        "model1 = torch.load('/content/drive/MyDrive/vgg_SCNN_DULR_w9.pth')\n",
        "\n",
        "\n",
        "model2 = collections.OrderedDict()\n",
        "\n",
        "layer_keys = [\n",
        "    'backbone.0', 'backbone.1', 'backbone.3', 'backbone.4',\n",
        "    'backbone.7', 'backbone.8', 'backbone.10', 'backbone.11',\n",
        "    'backbone.14', 'backbone.15', 'backbone.17', 'backbone.18',\n",
        "    'backbone.20', 'backbone.21', 'backbone.24', 'backbone.25',\n",
        "    'backbone.27', 'backbone.28', 'backbone.30', 'backbone.31',\n",
        "    'backbone.34', 'backbone.35', 'backbone.37', 'backbone.38',\n",
        "    'backbone.40', 'backbone.41', 'layer1.0', 'layer1.1',\n",
        "    'layer1.3', 'layer1.4', 'message_passing.up_down',\n",
        "    'message_passing.down_up', 'message_passing.left_right',\n",
        "    'message_passing.right_left', 'layer2.1', 'fc.0', 'fc.2'\n",
        "]\n",
        "\n",
        "for key in layer_keys:\n",
        "    model2[key + '.weight'] = model1['net'][key + '.weight']\n",
        "    if key + '.bias' in model1['net']:\n",
        "        model2[key + '.bias'] = model1['net'][key + '.bias']\n",
        "    if key + '.running_mean' in model1['net']:\n",
        "        model2[key + '.running_mean'] = model1['net'][key + '.running_mean']\n",
        "    if key + '.running_var' in model1['net']:\n",
        "        model2[key + '.running_var'] = model1['net'][key + '.running_var']\n",
        "\n",
        "model2['layer2.1.weight'] = model1['net']['layer2.1.weight']\n",
        "model2['layer2.1.bias'] = model1['net']['layer2.1.bias']\n",
        "\n",
        "model2['fc.0.weight'] = model1['net']['fc.0.weight']\n",
        "model2['fc.0.bias'] = model1['net']['fc.0.bias']\n",
        "\n",
        "model2['fc.2.weight'] = model1['net']['fc.2.weight']\n",
        "model2['fc.2.bias'] = model1['net']['fc.2.bias']\n",
        "\n",
        "\n",
        "\n",
        "save_name = os.path.join('/content/drive/Othercomputers/My MacBook Air/Desktop','experiments', 'vgg_SCNN_DULR_w9', 'vgg_SCNN_DULR_w9.pth')\n",
        "# save_name2 = os.path.join('/content/drive/MyDrive','experiments', 'exp10', 'exp10.pth')\n",
        "torch.save(model2, save_name)\n",
        "# torch.save(model2,save_name2)\n",
        "\n",
        "# load and save again\n",
        "net = SCNN(input_size=(800, 288), pretrained=False)\n",
        "d = torch.load(save_name)\n",
        "net.load_state_dict(d, strict=False)\n",
        "for m in net.backbone.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "\n",
        "\n",
        "save_dict = {\n",
        "    \"epoch\": 0,\n",
        "    \"net\": net.state_dict(),\n",
        "     \"optim\": None,\n",
        "    \"lr_scheduler\": None\n",
        "}\n",
        "\n",
        "if not os.path.exists(os.path.join('/content/drive/Othercomputers/My MacBook Air/Desktop/experiments', 'vgg_SCNN_DULR_w9')):\n",
        "    os.makedirs(os.path.join('/content/drive/Othercomputers/My MacBook Air/Desktop/experiments', 'vgg_SCNN_DULR_w9'), exist_ok=True)\n",
        "torch.save(save_dict, save_name)\n",
        "\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--exp_dir\", type=str, default=\"/content/drive/MyDrive/experiments/exp10\")\n",
        "    parser.add_argument(\"--resume\", \"-r\", action=\"store_true\")\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "args = parse_args()\n",
        "\n",
        "# ------------ config ------------\n",
        "exp_dir = args.exp_dir\n",
        "while exp_dir[-1]=='/':\n",
        "    exp_dir = exp_dir[:-1]\n",
        "exp_name = exp_dir.split('/')[-1]\n",
        "\n",
        "with open(os.path.join(exp_dir, \"cfg.json\")) as f:\n",
        "    exp_cfg = json.load(f)\n",
        "resize_shape = tuple(exp_cfg['dataset']['resize_shape'])\n",
        "\n",
        "device = torch.device(exp_cfg['device'])\n",
        "tensorboard = TensorBoard(exp_dir)\n",
        "# ------------ train data ------------\n",
        "# # CULane mean, std\n",
        "mean=(0.3598, 0.3653, 0.3662)\n",
        "std=(0.2573, 0.2663, 0.2756)\n",
        "# Imagenet mean, std\n",
        "# mean=(0.485, 0.456, 0.406)\n",
        "# std=(0.229, 0.224, 0.225)\n",
        "transform_train = Compose(Resize(resize_shape), Rotation(2), ToTensor(),\n",
        "                          Normalize(mean=mean, std=std))\n",
        "dataset_name = exp_cfg['dataset'].pop('dataset_name')\n",
        "\n",
        "# Dataset_Type = getattr(dataset, dataset_name)\n",
        "train_dataset = CULane(Dataset_Path[dataset_name], \"train\", transform_train)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=exp_cfg['dataset']['batch_size'], shuffle=True, collate_fn=train_dataset.collate, num_workers=8)\n",
        "try:\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=train_dataset.collate,num_workers=2)\n",
        "except Exception as e:\n",
        "    print(\"DataLoader initialization error:\", e)\n",
        "# ------------ val data ------------\n",
        "transform_val_img = Resize(resize_shape)\n",
        "transform_val_x = Compose(ToTensor(), Normalize(mean=mean, std=std))\n",
        "transform_val = Compose(transform_val_img, transform_val_x)\n",
        "val_dataset = CULane(Dataset_Path[dataset_name], \"val\", transform_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, collate_fn=val_dataset.collate, num_workers=4)\n",
        "\n",
        "# ------------ preparation ------------\n",
        "net = SCNN(resize_shape, pretrained=True)\n",
        "net = net.to(device)\n",
        "net = torch.nn.DataParallel(net)\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), **exp_cfg['optim'])\n",
        "lr_scheduler = PolyLR(optimizer, 0.9, **exp_cfg['lr_scheduler'])\n",
        "best_val_loss = 1e6\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    print(\"Train Epoch: {}\".format(epoch))\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    train_loss_seg = 0\n",
        "    train_loss_exist = 0\n",
        "    progressbar = tqdm(range(len(train_loader)))\n",
        "\n",
        "    for batch_idx, sample in enumerate(train_loader):\n",
        "        img = sample['img'].to(device)\n",
        "        segLabel = sample['segLabel'].to(device)\n",
        "        exist = sample['exist'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        seg_pred, exist_pred, loss_seg, loss_exist, loss = net(img, segLabel, exist)\n",
        "        if isinstance(net, torch.nn.DataParallel):\n",
        "            loss_seg = loss_seg.sum()\n",
        "            loss_exist = loss_exist.sum()\n",
        "            loss = loss.sum()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        iter_idx = epoch * len(train_loader) + batch_idx\n",
        "        train_loss = loss.item()\n",
        "        train_loss_seg = loss_seg.item()\n",
        "        train_loss_exist = loss_exist.item()\n",
        "        progressbar.set_description(\"batch loss: {:.3f}\".format(loss.item()))\n",
        "        progressbar.update(1)\n",
        "\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        tensorboard.scalar_summary(exp_name + \"/train_loss\", train_loss, iter_idx)\n",
        "        tensorboard.scalar_summary(exp_name + \"/train_loss_seg\", train_loss_seg, iter_idx)\n",
        "        tensorboard.scalar_summary(exp_name + \"/train_loss_exist\", train_loss_exist, iter_idx)\n",
        "        tensorboard.scalar_summary(exp_name + \"/learning_rate\", lr, iter_idx)\n",
        "\n",
        "    progressbar.close()\n",
        "    tensorboard.writer.flush()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        save_dict = {\n",
        "            \"epoch\": epoch,\n",
        "            \"net\": net.module.state_dict() if isinstance(net, torch.nn.DataParallel) else net.state_dict(),\n",
        "            \"optim\": optimizer.state_dict(),\n",
        "            \"lr_scheduler\": lr_scheduler.state_dict(),\n",
        "            \"best_val_loss\": best_val_loss\n",
        "        }\n",
        "        save_name = os.path.join(exp_dir, exp_name + '.pth')\n",
        "        torch.save(save_dict, save_name)\n",
        "        print(\"model is saved: {}\".format(save_name))\n",
        "\n",
        "    print(\"------------------------\\n\")\n",
        "\n",
        "\n",
        "def val(epoch):\n",
        "    global best_val_loss\n",
        "\n",
        "    print(\"Val Epoch: {}\".format(epoch))\n",
        "\n",
        "    net.eval()\n",
        "    val_loss = 0\n",
        "    val_loss_seg = 0\n",
        "    val_loss_exist = 0\n",
        "    progressbar = tqdm(range(len(val_loader)))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, sample in enumerate(val_loader):\n",
        "            img = sample['img'].to(device)\n",
        "            segLabel = sample['segLabel'].to(device)\n",
        "            exist = sample['exist'].to(device)\n",
        "\n",
        "            seg_pred, exist_pred, loss_seg, loss_exist, loss = net(img, segLabel, exist)\n",
        "            if isinstance(net, torch.nn.DataParallel):\n",
        "                loss_seg = loss_seg.sum()\n",
        "                loss_exist = loss_exist.sum()\n",
        "                loss = loss.sum()\n",
        "\n",
        "            # visualize validation every 5 frame, 50 frames in all\n",
        "            gap_num = 5\n",
        "            if batch_idx%gap_num == 0 and batch_idx < 50 * gap_num:\n",
        "                origin_imgs = []\n",
        "                seg_pred = seg_pred.detach().cpu().numpy()\n",
        "                exist_pred = exist_pred.detach().cpu().numpy()\n",
        "\n",
        "                for b in range(len(img)):\n",
        "                    img_name = sample['img_name'][b]\n",
        "                    img = cv2.imread(img_name)\n",
        "                    img = transform_val_img({'img': img})['img']\n",
        "\n",
        "                    lane_img = np.zeros_like(img)\n",
        "                    color = np.array([[255, 125, 0], [0, 255, 0], [0, 0, 255], [0, 255, 255]], dtype='uint8')\n",
        "\n",
        "                    coord_mask = np.argmax(seg_pred[b], axis=0)\n",
        "                    for i in range(0, 4):\n",
        "                        if exist_pred[b, i] > 0.5:\n",
        "                            lane_img[coord_mask==(i+1)] = color[i]\n",
        "                    img = cv2.addWeighted(src1=lane_img, alpha=0.8, src2=img, beta=1., gamma=0.)\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    lane_img = cv2.cvtColor(lane_img, cv2.COLOR_BGR2RGB)\n",
        "                    cv2.putText(lane_img, \"{}\".format([1 if exist_pred[b, i]>0.5 else 0 for i in range(4)]), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 1.1, (255, 255, 255), 2)\n",
        "                    origin_imgs.append(img)\n",
        "                    origin_imgs.append(lane_img)\n",
        "                tensorboard.image_summary(\"img_{}\".format(batch_idx), origin_imgs, epoch)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_loss_seg += loss_seg.item()\n",
        "            val_loss_exist += loss_exist.item()\n",
        "\n",
        "            progressbar.set_description(\"batch loss: {:.3f}\".format(loss.item()))\n",
        "            progressbar.update(1)\n",
        "\n",
        "    progressbar.close()\n",
        "    iter_idx = (epoch + 1) * len(train_loader)  # keep align with training process iter_idx\n",
        "    tensorboard.scalar_summary(\"val_loss\", val_loss, iter_idx)\n",
        "    tensorboard.scalar_summary(\"val_loss_seg\", val_loss_seg, iter_idx)\n",
        "    tensorboard.scalar_summary(\"val_loss_exist\", val_loss_exist, iter_idx)\n",
        "    tensorboard.writer.flush()\n",
        "\n",
        "    print(\"------------------------\\n\")\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        save_name = os.path.join(exp_dir, exp_name + '.pth')\n",
        "        copy_name = os.path.join(exp_dir, exp_name + '_best.pth')\n",
        "        shutil.copyfile(save_name, copy_name)\n",
        "\n",
        "\n",
        "def main():\n",
        "    global best_val_loss\n",
        "    if args.resume:\n",
        "        save_dict = torch.load(os.path.join(exp_dir, exp_name + '.pth'))\n",
        "        if isinstance(net, torch.nn.DataParallel):\n",
        "            net.module.load_state_dict(save_dict['net'])\n",
        "        else:\n",
        "            net.load_state_dict(save_dict['net'])\n",
        "        optimizer.load_state_dict(save_dict['optim'])\n",
        "        lr_scheduler.load_state_dict(save_dict['lr_scheduler'])\n",
        "        start_epoch = save_dict['epoch'] + 1\n",
        "        best_val_loss = save_dict.get(\"best_val_loss\", 1e6)\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "\n",
        "    exp_cfg['MAX_EPOCHES'] = int(np.ceil(exp_cfg['lr_scheduler']['max_iter'] / len(train_loader)))\n",
        "    for epoch in range(start_epoch, exp_cfg['MAX_EPOCHES']):\n",
        "        train(epoch)\n",
        "        if epoch % 1 == 0:\n",
        "            print(\"\\nValidation For Experiment: \", exp_dir)\n",
        "            print(time.strftime('%H:%M:%S', time.localtime()))\n",
        "            val(epoch)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "yBkdaJn3uoAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--exp_dir\", type=str, default=\"/content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10\")\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "# ------------ config ------------\n",
        "args = parse_args()\n",
        "exp_dir = args.exp_dir\n",
        "exp_name = exp_dir.split('/')[-1]\n",
        "\n",
        "with open(os.path.join(exp_dir, \"cfg.json\")) as f:\n",
        "    exp_cfg = json.load(f)\n",
        "resize_shape = tuple(exp_cfg['dataset']['resize_shape'])\n",
        "device = torch.device('cuda')\n",
        "\n",
        "\n",
        "def split_path(path):\n",
        "    \"\"\"split path tree into list\"\"\"\n",
        "    folders = []\n",
        "    while True:\n",
        "        path, folder = os.path.split(path)\n",
        "        if folder != \"\":\n",
        "            folders.insert(0, folder)\n",
        "        else:\n",
        "            if path != \"\":\n",
        "                folders.insert(0, path)\n",
        "            break\n",
        "    return folders\n",
        "\n",
        "\n",
        "# ------------ data and model ------------\n",
        "# CULane mean, std\n",
        "mean=(0.3598, 0.3653, 0.3662)\n",
        "std=(0.2573, 0.2663, 0.2756)\n",
        "# Imagenet mean, std\n",
        "# mean = (0.485, 0.456, 0.406)\n",
        "# std = (0.229, 0.224, 0.225)\n",
        "dataset_name = exp_cfg['dataset'].pop('dataset_name')\n",
        "# Dataset_Type = getattr(dataset, dataset_name)\n",
        "transform = Compose(Resize(resize_shape), ToTensor(),\n",
        "                    Normalize(mean=mean, std=std))\n",
        "test_dataset = CULane(Dataset_Path[dataset_name], \"test\", transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=test_dataset.collate, num_workers=4)\n",
        "\n",
        "net = SCNN(resize_shape, pretrained=False)\n",
        "save_name = os.path.join(exp_dir, exp_dir.split('/')[-1] + '_best.pth')\n",
        "save_dict = torch.load('/content/drive/MyDrive/exp10_best.pth', map_location='cpu')\n",
        "print(\"\\nloading\", save_name, \"...... From Epoch: \", save_dict['epoch'])\n",
        "net.load_state_dict(save_dict['net'])\n",
        "net = torch.nn.DataParallel(net.to(device))\n",
        "net.eval()\n",
        "\n",
        "# ------------ test ------------\n",
        "out_path = os.path.join(exp_dir, \"coord_output\")\n",
        "evaluation_path = os.path.join(exp_dir, \"evaluate\")\n",
        "if not os.path.exists(out_path):\n",
        "    os.mkdir(out_path)\n",
        "if not os.path.exists(evaluation_path):\n",
        "    os.mkdir(evaluation_path)\n",
        "\n",
        "progressbar = tqdm(range(len(test_loader)))\n",
        "with torch.no_grad():\n",
        "    for batch_idx, sample in enumerate(test_loader):\n",
        "        img = sample['img'].to(device)\n",
        "        img_name = sample['img_name']\n",
        "\n",
        "        seg_pred, exist_pred = net(img)[:2]\n",
        "        seg_pred = F.softmax(seg_pred, dim=1)\n",
        "        seg_pred = seg_pred.detach().cpu().numpy()\n",
        "        exist_pred = exist_pred.detach().cpu().numpy()\n",
        "\n",
        "        for b in range(len(seg_pred)):\n",
        "            seg = seg_pred[b]\n",
        "            exist = [1 if exist_pred[b, i] > 0.5 else 0 for i in range(4)]\n",
        "            lane_coords = prob2lines_CULane(seg, exist, resize_shape=(590, 1640), y_px_gap=20, pts=18)\n",
        "\n",
        "            path_tree = split_path(img_name[b])\n",
        "            save_dir, save_name = path_tree[-3:-1], path_tree[-1]\n",
        "            save_dir = os.path.join(out_path, *save_dir)\n",
        "            save_name = save_name[:-3] + \"lines.txt\"\n",
        "            save_name = os.path.join(save_dir, save_name)\n",
        "            if not os.path.exists(save_dir):\n",
        "                os.makedirs(save_dir)\n",
        "\n",
        "            with open(save_name, \"w\") as f:\n",
        "                for l in lane_coords:\n",
        "                    for (x, y) in l:\n",
        "                        print(\"{} {}\".format(x, y), end=\" \", file=f)\n",
        "                    print(file=f)\n",
        "\n",
        "        progressbar.update(1)\n",
        "progressbar.close()"
      ],
      "metadata": {
        "id": "Xne1CmMu237V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f16073d-5ac1-4193-fd54-8a61c525d8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "loading /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/exp10_best.pth ...... From Epoch:  13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 53/53 [13:42<00:00, 15.53s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------- For building CPP files, Run before Eval-------#\n",
        "%%shell\n",
        "cd /content/drive/MyDrive/Project/SCNN_Pytorch/utils/lane_evaluation/CULane\n",
        "mkdir build && cd build\n",
        "cmake ..\n",
        "make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW3VE3qLd7kk",
        "outputId": "2605eaf7-6282-43a1-a864-b864e233b708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenCV: /usr (found version \"4.5.4\") \n",
            "-- Configuring done (2.6s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/Project/SCNN_Pytorch/utils/lane_evaluation/CULane/build\n",
            "[-20%] \u001b[32mBuilding CXX object CMakeFiles/evaluate.dir/src/evaluate.cpp.o\u001b[0m\n",
            "[  0%] \u001b[32mBuilding CXX object CMakeFiles/evaluate.dir/src/counter.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/evaluate.dir/src/lane_compare.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/evaluate.dir/src/spline.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32m\u001b[1mLinking CXX executable /content/drive/MyDrive/Project/SCNN_Pytorch/utils/lane_evaluation/CULane/evaluate\u001b[0m\n",
            "[ 60%] Built target evaluate\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- evaluate ----\n",
        "import os\n",
        "os.system(\"sh /content/drive/MyDrive/Project/SCNN_Pytorch/utils/lane_evaluation/CULane/Run.sh \" + exp_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOKhZLorQSAo",
        "outputId": "c77abe4b-0cf3-4cb5-e802-ec85ff20e97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/drive/MyDrive/Project/SCNN_Pytorch/utils/lane_evaluation/CULane/Run.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01yMsGJ0fDqe",
        "outputId": "2b0f2c73-58e8-4b41-b24e-34dc567ad820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Configuration---------\n",
            "using multi-thread, num:20\n",
            "anno_dir: /content/drive/MyDrive/CULane_path/\n",
            "detect_dir: /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/coord_output/\n",
            "im_dir: /content/drive/MyDrive/CULane_path/\n",
            "list_im_file: /content/drive/MyDrive/CULane_path/list/test_split/test0_normal.txt\n",
            "width_lane: 30\n",
            "iou_threshold: 0.5\n",
            "im_width: 1640\n",
            "im_height: 590\n",
            "-----------------------------------\n",
            "Evaluating the results...\n",
            "list images num: 567\n",
            "tp: 1640 fp: 259 fn: 267\n",
            "finished process file\n",
            "precision: 0.863612\n",
            "recall: 0.85999\n",
            "Fmeasure: 0.861797\n",
            "----------------------------------\n",
            "------------Configuration---------\n",
            "using multi-thread, num:20\n",
            "anno_dir: /content/drive/MyDrive/CULane_path/\n",
            "detect_dir: /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/coord_output/\n",
            "im_dir: /content/drive/MyDrive/CULane_path/\n",
            "list_im_file: /content/drive/MyDrive/CULane_path/list/test_split/test1_crowd.txt\n",
            "width_lane: 30\n",
            "iou_threshold: 0.5\n",
            "im_width: 1640\n",
            "im_height: 590\n",
            "-----------------------------------\n",
            "Evaluating the results...\n",
            "list images num: 1318\n",
            "tp: 2810 fp: 1410 fn: 1558\n",
            "finished process file\n",
            "precision: 0.665877\n",
            "recall: 0.643315\n",
            "Fmeasure: 0.654401\n",
            "----------------------------------\n",
            "------------Configuration---------\n",
            "using multi-thread, num:20\n",
            "anno_dir: /content/drive/MyDrive/CULane_path/\n",
            "detect_dir: /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/coord_output/\n",
            "im_dir: /content/drive/MyDrive/CULane_path/\n",
            "list_im_file: /content/drive/MyDrive/CULane_path/list/test_split/test2_hlight.txt\n",
            "width_lane: 30\n",
            "iou_threshold: 0.5\n",
            "im_width: 1640\n",
            "im_height: 590\n",
            "-----------------------------------\n",
            "Evaluating the results...\n",
            "list images num: 292\n",
            "tp: 613 fp: 363 fn: 412\n",
            "finished process file\n",
            "precision: 0.628074\n",
            "recall: 0.598049\n",
            "Fmeasure: 0.612694\n",
            "----------------------------------\n",
            "------------Configuration---------\n",
            "using multi-thread, num:20\n",
            "anno_dir: /content/drive/MyDrive/CULane_path/\n",
            "detect_dir: /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/coord_output/\n",
            "im_dir: /content/drive/MyDrive/CULane_path/\n",
            "list_im_file: /content/drive/MyDrive/CULane_path/list/test_split/test3_shadow.txt\n",
            "width_lane: 30\n",
            "iou_threshold: 0.5\n",
            "im_width: 1640\n",
            "im_height: 590\n",
            "-----------------------------------\n",
            "Evaluating the results...\n",
            "list images num: 16\n",
            "tp: 0 fp: 0 fn: 0\n",
            "no positive detection\n",
            "no ground truth positive\n",
            "finished process file\n",
            "precision: -1\n",
            "recall: -1\n",
            "Fmeasure: -1\n",
            "----------------------------------\n",
            "------------Configuration---------\n",
            "using multi-thread, num:20\n",
            "anno_dir: /content/drive/MyDrive/CULane_path/\n",
            "detect_dir: /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/coord_output/\n",
            "im_dir: /content/drive/MyDrive/CULane_path/\n",
            "list_im_file: /content/drive/MyDrive/CULane_path/list/test_split/test4_noline.txt\n",
            "width_lane: 30\n",
            "iou_threshold: 0.5\n",
            "im_width: 1640\n",
            "im_height: 590\n",
            "-----------------------------------\n",
            "Evaluating the results...\n",
            "list images num: 316\n",
            "tp: 567 fp: 431 fn: 497\n",
            "finished process file\n",
            "precision: 0.568136\n",
            "recall: 0.532895\n",
            "Fmeasure: 0.549952\n",
            "----------------------------------\n",
            "------------Configuration---------\n",
            "using multi-thread, num:20\n",
            "anno_dir: /content/drive/MyDrive/CULane_path/\n",
            "detect_dir: /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/coord_output/\n",
            "im_dir: /content/drive/MyDrive/CULane_path/\n",
            "list_im_file: /content/drive/MyDrive/CULane_path/list/test_split/test5_arrow.txt\n",
            "width_lane: 30\n",
            "iou_threshold: 0.5\n",
            "im_width: 1640\n",
            "im_height: 590\n",
            "-----------------------------------\n",
            "Evaluating the results...\n",
            "list images num: 136\n",
            "tp: 302 fp: 98 fn: 113\n",
            "finished process file\n",
            "precision: 0.755\n",
            "recall: 0.727711\n",
            "Fmeasure: 0.741104\n",
            "----------------------------------\n",
            "------------Configuration---------\n",
            "using multi-thread, num:20\n",
            "anno_dir: /content/drive/MyDrive/CULane_path/\n",
            "detect_dir: /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/coord_output/\n",
            "im_dir: /content/drive/MyDrive/CULane_path/\n",
            "list_im_file: /content/drive/MyDrive/CULane_path/list/test_split/test6_curve.txt\n",
            "width_lane: 30\n",
            "iou_threshold: 0.5\n",
            "im_width: 1640\n",
            "im_height: 590\n",
            "-----------------------------------\n",
            "Evaluating the results...\n",
            "list images num: 11\n",
            "tp: 0 fp: 0 fn: 0\n",
            "no positive detection\n",
            "no ground truth positive\n",
            "finished process file\n",
            "precision: -1\n",
            "recall: -1\n",
            "Fmeasure: -1\n",
            "----------------------------------\n",
            "------------Configuration---------\n",
            "using multi-thread, num:20\n",
            "anno_dir: /content/drive/MyDrive/CULane_path/\n",
            "detect_dir: /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/coord_output/\n",
            "im_dir: /content/drive/MyDrive/CULane_path/\n",
            "list_im_file: /content/drive/MyDrive/CULane_path/list/test_split/test7_cross.txt\n",
            "width_lane: 30\n",
            "iou_threshold: 0.5\n",
            "im_width: 1640\n",
            "im_height: 590\n",
            "-----------------------------------\n",
            "Evaluating the results...\n",
            "list images num: 521\n",
            "tp: 0 fp: 116 fn: 0\n",
            "no ground truth positive\n",
            "finished process file\n",
            "precision: 0\n",
            "recall: -1\n",
            "Fmeasure: 0\n",
            "----------------------------------\n",
            "------------Configuration---------\n",
            "using multi-thread, num:20\n",
            "anno_dir: /content/drive/MyDrive/CULane_path/\n",
            "detect_dir: /content/drive/MyDrive/Project/SCNN_Pytorch/experiments/exp10/coord_output/\n",
            "im_dir: /content/drive/MyDrive/CULane_path/\n",
            "list_im_file: /content/drive/MyDrive/CULane_path/list/test_split/test8_night.txt\n",
            "width_lane: 30\n",
            "iou_threshold: 0.5\n",
            "im_width: 1640\n",
            "im_height: 590\n",
            "-----------------------------------\n",
            "Evaluating the results...\n",
            "list images num: 180\n",
            "tp: 252 fp: 220 fn: 333\n",
            "finished process file\n",
            "precision: 0.533898\n",
            "recall: 0.430769\n",
            "Fmeasure: 0.476821\n",
            "----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "\n",
        "net = SCNN(input_size=(800, 288), pretrained=False)\n",
        "mean=(0.3598, 0.3653, 0.3662) # CULane mean, std\n",
        "std=(0.2573, 0.2663, 0.2756)\n",
        "transform_img = Resize((800, 288))\n",
        "transform_to_net = Compose(ToTensor(), Normalize(mean=mean, std=std))\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--img_path\", '-i', type=str, default=\"/content/demo3.png\", help=\"Path to demo img\")\n",
        "    parser.add_argument(\"--weight_path\", '-w', type=str, default = '/content/gdrive/MyDrive/exp10_best.pth', help=\"Path to model weights\")\n",
        "    parser.add_argument(\"--visualize\", '-v', action=\"store_true\", default=False, help=\"Visualize the result\")\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    img_path = args.img_path\n",
        "    weight_path = args.weight_path\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = transform_img({'img': img})['img']\n",
        "    x = transform_to_net({'img': img})['img']\n",
        "    x.unsqueeze_(0)\n",
        "\n",
        "    save_dict = torch.load(weight_path, map_location='cpu')\n",
        "    net.load_state_dict(save_dict['net'])\n",
        "    net.eval()\n",
        "\n",
        "    seg_pred, exist_pred = net(x)[:2]\n",
        "    seg_pred = seg_pred.detach().cpu().numpy()\n",
        "    exist_pred = exist_pred.detach().cpu().numpy()\n",
        "    seg_pred = seg_pred[0]\n",
        "    exist = [1 if exist_pred[0, i] > 0.5 else 0 for i in range(4)]\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    lane_img = np.zeros_like(img)\n",
        "    color = np.array([[255, 125, 0], [0, 255, 0], [0, 0, 255], [0, 255, 255]], dtype='uint8')\n",
        "    coord_mask = np.argmax(seg_pred, axis=0)\n",
        "    for i in range(0, 4):\n",
        "        if exist_pred[0, i] > 0.5:\n",
        "            lane_img[coord_mask == (i + 1)] = color[i]\n",
        "    img = cv2.addWeighted(src1=lane_img, alpha=0.8, src2=img, beta=1., gamma=0.)\n",
        "    cv2.imwrite(\"demo_result3.png\", img)\n",
        "\n",
        "    for x in prob2lines_CULane(seg_pred, exist):\n",
        "        print(x)\n",
        "\n",
        "    if args.visualize:\n",
        "        print([1 if exist_pred[0, i] > 0.5 else 0 for i in range(4)])\n",
        "        cv2.imshow(\"\", img)\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2nV2qhHt4u-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d2e8b4-53b3-4bb4-e5bb-6620d5b16405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[343.0, 287], [357.0, 267], [369.0, 247], [387.0, 227], [327.0, 207], [374.0, 187], [422.0, 167]]\n",
            "[[690.0, 287], [658.0, 267], [611.0, 247], [563.0, 227], [500.0, 207], [463.0, 187]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kNYmVgghVAlz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}